{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Haarcascade Face Recognition\n",
        "Code by:\n",
        "Indira Puspita Margariza \n",
        "\n",
        "This code is used to detect face within image and then extract the cropped face.\n",
        "This code can also detect eyes, but the accuracy is not that good.\n",
        "To be able to use this result of face detection for face verification usage it needs face embeddings extractor model to compare 2 images. \n",
        "\n",
        "Pretrained haarcascade classifier from OpenCV is used here."
      ],
      "metadata": {
        "id": "2R6hSJtvV4Fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YIA7CiDuhikv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/opencv/opencv.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxxSknM2-BpV",
        "outputId": "dd773924-e8a9-4b92-95b2-5e2de6c4d749"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'opencv'...\n",
            "remote: Enumerating objects: 312019, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 312019 (delta 3), reused 40 (delta 1), pack-reused 311952\u001b[K\n",
            "Receiving objects: 100% (312019/312019), 499.48 MiB | 21.17 MiB/s, done.\n",
            "Resolving deltas: 100% (217180/217180), done.\n",
            "Checking out files: 100% (7017/7017), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing pretrained classifier for detection particular object paths\n",
        "#In this face detection case, we will need a classifier for detecting face, eyes, and lips.\n",
        "folder_path = \"opencv/data/haarcascades/\"\n",
        "detector_files = {\n",
        "\t\"face\": \"haarcascade_frontalface_default.xml\",\n",
        "\t\"eyes\": \"haarcascade_eye.xml\"\n",
        "}\n",
        "#Initializing sample images folder\n",
        "#There are several images used, those contain with single face or multiface.\n",
        "image_paths = sorted(glob.glob(\"images/*.jpg\"))\n"
      ],
      "metadata": {
        "id": "Ycpf2NSPqKiQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load pretrained classifier for face, eye, and smile detection\n",
        "detectors = {}\n",
        "for name, file_path in detector_files.items():\n",
        "  detectors[name] = cv2.CascadeClassifier(folder_path + file_path)"
      ],
      "metadata": {
        "id": "yqIMFltX-V4K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterate process through the whole image folder\n",
        "for image_path in image_paths:\n",
        "  #load and preprocess the input image to suit the detector\n",
        "  image = cv2.imread(image_path)\n",
        "  image_save = np.copy(image)\n",
        "  print(image_path)\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  \n",
        "  #do inference process to detect faces in the image\n",
        "  face_bboxes = detectors[\"face\"].detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=2, minSize=(150, 150), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "  \n",
        "  #iterate through face bounding boxes\n",
        "  for idx, (x, y, w, h) in enumerate(face_bboxes):\n",
        "    #crop face bounding_box\n",
        "    face = image[y:y+h, x:x+w]\n",
        "    face_crop_save = \"face-result/\" + image_path.split(\"/\")[-1].split(\".\")[0] + \"_\" + str(idx) + \".jpg\"\n",
        "    cv2.imwrite(face_crop_save, face)\n",
        "    gray_face = gray_image[y:y+h, x:x+w]\n",
        "\n",
        "    #draw bounding box in original image\n",
        "    image_save = cv2.rectangle(image_save, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    \n",
        "    #do inference to detect eye\n",
        "    eyes_bboxes = detectors[\"eyes\"].detectMultiScale(gray_face, scaleFactor=1.2, minNeighbors=7, minSize=(40, 40), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    for (x_e, y_e, w_e, h_e) in eyes_bboxes:\n",
        "      image_save = cv2.rectangle(image_save, (x_e+x, y_e+y), (x_e+x+w_e, y_e+y+h_e), (0, 255, 255), 2)\n",
        "\n",
        "  cv2.imwrite(\"images-result/\" + image_path.split('/')[-1], image_save)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zpk6I0pE6Zg",
        "outputId": "1480ea10-b606-48c3-cde1-863d16705451"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/13_Interview_Interview_On_Location_13_301.jpg\n",
            "images/13_Interview_Interview_On_Location_13_852.jpg\n",
            "images/20_Family_Group_Family_Group_20_739.jpg\n",
            "images/20_Family_Group_Family_Group_20_775.jpg\n",
            "images/20_Family_Group_Family_Group_20_843.jpg\n",
            "images/29_Students_Schoolkids_Students_Schoolkids_29_380.jpg\n",
            "images/29_Students_Schoolkids_Students_Schoolkids_29_42.jpg\n",
            "images/29_Students_Schoolkids_Students_Schoolkids_29_74.jpg\n",
            "images/7_Cheering_Cheering_7_239.jpg\n",
            "images/7_Cheering_Cheering_7_500.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iec7MtZ17xd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}